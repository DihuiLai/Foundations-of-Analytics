%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Lachaise Assignment
% LaTeX Template
% Version 1.0 (26/6/2018)
%
% This template originates from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Marion Lachaise & François Févotte
% Vel (vel@LaTeXTemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------


\documentclass{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr, graphicx}
\fancyhf{}

\rhead{\includegraphics[width=8cm]{washulogo.eps}}
\lhead{T81-574: Foundations of Analytics}

\input{structure.tex} % Include the file specifying the document structure and custom commands

%----------------------------------------------------------------------------------------
%	ASSIGNMENT INFORMATION
%-----------------------------------the-----------------------------------------------------

%----------------------------------------------------------------------------------------
\usepackage{color}
\usepackage{listings}
\usepackage{setspace}
\definecolor{Code}{rgb}{0,0,0}
\definecolor{Decorators}{rgb}{0.5,0.5,0.5}
\definecolor{Numbers}{rgb}{0.5,0,0}
\definecolor{MatchingBrackets}{rgb}{0.25,0.5,0.5}
\definecolor{Keywords}{rgb}{0,0,1}
\definecolor{self}{rgb}{0,0,0}
\definecolor{Strings}{rgb}{0,0.63,0}
\definecolor{Comments}{rgb}{0,0.63,1}
\definecolor{Backquotes}{rgb}{0,0,0}
\definecolor{Classname}{rgb}{0,0,0}
\definecolor{FunctionName}{rgb}{0,0,0}
\definecolor{Operators}{rgb}{0,0,0}
\definecolor{Background}{rgb}{0.98,0.98,0.98}
\lstdefinelanguage{Python}{
numbers=left,
numberstyle=\footnotesize,
numbersep=1em,
xleftmargin=1em,
framextopmargin=2em,
framexbottommargin=2em,
showspaces=false,
showtabs=false,
showstringspaces=false,
frame=l,
tabsize=4,
% Basic
basicstyle=\ttfamily\small\setstretch{1},
backgroundcolor=\color{Background},
% Comments
commentstyle=\color{Comments}\slshape,
% Strings
stringstyle=\color{Strings},
morecomment=[s][\color{Strings}]{"""}{"""},
morecomment=[s][\color{Strings}]{'''}{'''},
% keywords
morekeywords={import,from,class,def,for,while,if,is,in,elif,else,not,and,or,print,break,continue,return,True,False,None,access,as,,del,except,exec,finally,global,import,lambda,pass,print,raise,try,assert},
keywordstyle={\color{Keywords}\bfseries},
% additional keywords
morekeywords={[2]@invariant,pylab,numpy,np,scipy},
keywordstyle={[2]\color{Decorators}\slshape},
emph={self},
emphstyle={\color{self}\slshape},
%
}
\title{Problem Set - Logistic Regression} % Title of the assignment

\begin{document}

\maketitle % Print the title
\thispagestyle{fancy}
\pagestyle{fancy}
%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------

\section{The Gradient and Hessian Matrix of Logistic Regression}
Given n observation $y_1$, $y_2$ ..., $y_n$ that follows Bernoulli Distribution and the corresponding predictor vectors $\vec{x}_1$, $\vec{x}_2$, ..., $\vec{x}_n$, here $\vec{x}_{i}$ has $m$ components $\vec{x}_{i}=[x_{i1}, x_{i2}, ...x_{ij}, ...x_{im}]$. The total likelihood is therefore $L(y_1, y_2, .... y_n, p_1, p_2, ... ,p_n)=\prod\limits_{i=1}^n {p_i}^{y_i} (1-p_i)^{1-y_i}$. Assume $p_i$ is estimated by a logistic function $p_i=\frac{1}{1+\exp(-\vec{\beta}\cdot{\vec{x}_i})}$

\begin{enumerate}
\item Prove that the log-likelihood function $\ell=\sum\limits_{i=1}^n \left( y_i (\vec{x}_i \cdot \vec{\beta})-\log (1+\exp({\vec{x}_i \cdot \vec{\beta}}))\right)$?
\item Prove that $\frac{\partial \vec{x}_i \cdot \vec{\beta}}{\partial \beta_j}=x_{ij} $. 
\item  Prove that \begin{align*}
{\frac{\partial\ell}{\partial\beta_j}}
&={\sum_{i=1}^{n}\left (y^i-\frac{1}{1+\exp(-\vec{\beta}\cdot\vec{x}^i)} \right) x_{j}^{i}} \text{ , } {j=1, 2, 3, ...,m}
\end{align*}.
\item Use the results from (3) to calculate the Hessian matrix and prove that 
\begin{align*}
\mathnormal{\frac{\partial^2\ell}{\partial\beta_a\partial\beta_b}}=\mathnormal{-\sum_{i=1}^{n}x_b^i p_i (1-p_i)x_a^i}\\
\end{align*}
\item Prove that the jth component of the column matrix $\nabla\ell={X}^T(y-p)$ is the same as ${\frac{\partial\ell}{\partial\beta_j}}$, here$y$ and $p$ are column vectors $y=[y_1, y_2, ..., y_n]^T$, $p=[p_1, p_2, ..., p_n]^T$. $X$ is the predictor matrix 
\begin{align*}
{X}=  \begin{bmatrix}
    {x_{11}} & x_{12} &\dots &x_{1j}  &\dots &x_{1m} \\
    {x_{21}} & x_{22} &\dots &x_{2j}  &\dots &x_{2m} \\
    & & \ddots & &\\
    {x_{n1}} & x_{n2} &\dots &x_{nj}  &\dots &x_{nm} \\
  \end{bmatrix}
\end{align*}

\item Prove that $ath$ row and $bth$ column of $\mathbf{H}$, $\mathbf{H}_{ab}=\mathnormal{-\sum_{i=1}^{n}x_b^i p_i (1-p_i)x_a^i}$, where
\begin{align*}
\mathbf{H}&={-X^TWX}\text{, } 
{W}=  \begin{bmatrix}
    {p_1 (1-p_1)} & & \\
    & \ddots & \\
    & & {p_n (1-p_n)}
  \end{bmatrix}
\end{align*}
\end{enumerate}


\end{document}
